% Packages & Document Configurations
\documentclass{report_template}
\usepackage{dirtree}

% Authors & Supervisor
\firstauthor{Andreas Carelius Brustad}

\secondauthor{Håkon Bekken}

\thirdauthor{Johannes Husevåg Standal}

% Report Title & Subtitle
\title{Bay City oil spill simulation}

\subtitle{Course: \textbf{INF202}\\ Project assignment in advanced programming}

% Filiations
\university{Norwegian University of Life Sciences (NMBU)}
\degree{}
\school{}
\course{}

% Local & Date
\date{Norway, \monthname[\month] \number\year}

\begin{document}

% Covers
\include{Covers/00-Cover}

% Roman numeration
\pagenumbering{roman}

% List of contents, figures, and tables
\tableofcontents\blankpage

% Arabic numeration
\pagenumbering{arabic}

% Chapters
\chapter{Introduction}\label{ch:introduction}
Computer simulations are widely used in science and engineering to model complex systems and phenomena. 
They allow researchers to analyze and predict the behavior of systems under various conditions,
providing insights that may be difficult or impossible to obtain through traditional experimental methods.
The problem given of an oil spill has a real world implementation and are of significant for environmental concern. There are multiple examples like the Deepwater Horizon oil spill in 2010 \cite{DeepwaterHorizon}, where computational simulations was crucial in order to predict where surface oil would go, aiding skimming, booming, and shoreline protection.
\\
\begin{figure}[H]
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{Figures/deepwater-horizonbp-oil-spill.jpg}
  \captionof{figure}{Deepwater Horizon oil spill
  \parencite{DeepwaterHorizonOilSpill}}\label{fig:Deepwater Horizon BP oil spill}
\end{minipage}%
\begin{minipage}{.55\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{Figures/BayCity.png}
  \captionof{figure}{Bay city
  \parencite{Baycity}}\label{fig:Bay city from task}
\end{minipage}
\end{figure}

Our simulation aims to model oil trajectory and spread forecasting in Bay city.
Outside Bay city is a fishing ground that are voulnerable to oil spills.
This report will discuss the mathematical models used to represent the oil spill dynamics,
the numerical methods to solve these models, and the implementation of the simulation.
\newpage

\chapter{Overall problem and solution}

\section{Problem Description}
The fishing town of \emph{Bay City} has reported an oil spill from one of their ships.
The objective of the simulation is to assess the impact of the oil spill on the surrounding
fishing grounds and to determine appropriate measures to protect the local fish population.

An external group of researchers has provided a simplified two-dimensional flow field that is used
to approximate ocean currents in the region. In addition there is provided a two-dimensional map
of Bay City from the file  \texttt{bay.msh}. The data includes the coastline and ocean for the region.

\section{Initialisation}

When a new simulation object is created, a mesh file is loaded from the configuration file.
The mesh consists of a collection of cells (triangles for the ocean and lines for the coastline). 
Each cell stores a scalar value representing the oil density within
the area of the cell.

The initial oil distribution is centered at the spatial point
\begin{align*}
\vec{x}^{\star} = (x^{\star}, y^{\star})^{\top} &= (0.35, 0.45)^{\top},
\intertext{and is defined by the function}
u(t=0,\vec{x}) &= \exp\left(-\frac{\|\vec{x}-\vec{x}^{\star}\|^{2}}{0.01}\right),
\end{align*}
where $u(t,\vec{x})$ denotes the oil density at position $\vec{x}$ at time $t=0$.
The oil density is evaluated at the centerpoint of each cell and stored as the initial oil density value.

\section{Velocity field}
The vector field defines the direction and magnitude of oil flow at each cell.
The simplified ocean currents are given by this formula
\[
\vec{v}(\vec{x}, t) =
\begin{pmatrix}
y - 0.2x \\
-x
\end{pmatrix}.
\]
 
The simulation supports a parameter for time $t$ to account for any development in the ocean currents. 
This is not used in the current formula, but enables the programs extendebility.
If the vectorfield is time-independent this drastically increases the effectiveness of precomputated values.
This assumption is the backbone of the optimized faucet simulation. 

\section{Oil Transfer}

Let $u_i^n$ be the oil density in cell $i$ (area $A_i$) at time $t^n$.  
Each edge $\ell$ of cell $i$ has a scaled outward normal $\vec{\nu}_{i,\ell}$ pointing toward its neighbor $\text{ngh}_\ell$.

The velocity at each edge is the average of the velocities at its endpoints:
\[
\vec{v}_{i,\ell}^n = \frac{1}{2} \big( \vec{v}(\vec{x}_i,t^n) + \vec{v}(\vec{x}_{\text{ngh}_\ell},t^n) \big)
\]

The flux through an edge is defined as
\[
g(a,b,\vec{\nu},\vec{v}) =
\begin{cases}
a \, \langle \vec{v}, \vec{\nu} \rangle, & \text{if } \langle \vec{v}, \vec{\nu} \rangle > 0,\\
b \, \langle \vec{v}, \vec{\nu} \rangle, & \text{else}.
\end{cases}
\]

The flux contribution from edge $\ell$ is
\[
F_i^{(\text{ngh}_\ell,n)} = -\frac{\Delta t}{A_i} \, g(u_i^n, u_{\text{ngh}_\ell}^n, \vec{\nu}_{i,\ell}, \vec{v}_{i,\ell}^n)
\]

These edge contributions are first computed and stored. Then the oil density is updated for cell $i$ as
\[
u_i^{n+1} = u_i^n + \sum_{\ell=1}^{3} F_i^{(\text{ngh}_\ell,n)}
\]

Each cell exchanges oil with its neighbors through edges, using the flux function. Updates are calculated first for all cells, then applied simultaneously.

\section{Simulation types}
\subsection{Main simulation}
When the simulation starts, the solver initializes the values according to the provided functions. 
The mesh connects cells that share an edge as neighbors, storing a reference to each neighbor in a dictionary within the cell. 
Each entry in this dictionary associates a neighbor cell with the corresponding outward-pointing scaled normal vector, 
which points from the main cell toward that neighbor.
Given a total simulation time $t_{\text{end}}$ and
$N$ time steps, the time step size is
\[
\Delta t = \frac{t_{\text{end}}}{N}.
\]

After initialization, the solver checks whether it can run the optimized faucet simulation and produce the same result. 
If the criteria are not met, it falls back to the standard simulation.
\subsection{Standard Simulation}

For a time-dependent velocity field $\vec{v}(\vec{x},t)$, the above fluxes are
recomputed at every time step. At each timestep $t^n = n\Delta t$, fluxes are evaluated for all triangle cells,
and the change in oil densities are stored in a buffer variable. After all the cells has calculated
their update value, they add it to their stored oil density

\subsection{Faucet Simulation}

When the velocity field is time-independent, its time derivative vanishes,
and the velocity at each cell remains constant for all times.
\[
\frac{\partial \vec{v}}{\partial t} = [0,0],
\]
This means that all properties associated with a cell
can be precomputed before the simulation starts using the given formulas.

The flux direction across an edge is determined by
\[
\langle \vec{v}_{I(\mathrm{ngh})}, \vec{\nu}_{I(\mathrm{ngh})} \rangle.
\]

We only consider flow out of a cell and into its neighbour. 
The flux direction will align with the velocity if $0<direction$.


For each such outgoing edge, a \emph{faucet} from cell \(I\) to cell

\(\text{ngh}\) is defined.  
Each faucet is characterized by two constant coefficients,
\[
\text{flow}_{I\to\text{ngh}}
= \frac{\Delta t}{A_I}
\langle \vec{v}_{I,\text{ngh}}, \vec{\nu}_{I,\text{ngh}} \rangle,
\qquad
\text{flow}_{\text{ngh}\to I}
= \frac{\Delta t}{A_{\text{ngh}}}
\langle \vec{v}_{I,\text{ngh}}, \vec{\nu}_{I,\text{ngh}} \rangle,
\]
where \(A\) the cell areas.

During a single time step, the oil density update induced by one faucet
\((I \rightarrow \text{ngh})\) is given by
\[
u_I^{n+1} = u_I^n - u_I^n\,\text{flow}_{I\to\text{ngh}},
\]
\[
u_{\text{ngh}}^{n+1} = u_{\text{ngh}}^n + u_I^n\,\text{flow}_{\text{ngh}\to I}.
\]

The total update of a cell is obtained by applying all faucets connected to it.
After all faucet contributions have been accumulated, the oil densities of all
cells are updated simultaneously.

\section{Conservation}

This formulation guarantees conservation of the total oil amount.
For each faucet, the oil removed from the source cell is exactly redistributed
to the neighboring cell, with changes scaled by the corresponding cell areas.
Since conservation holds locally for every faucet, it also holds globally over
the entire computational domain.

\chapter{User guide}



\chapter{Code structre}

\section{Folder structre}


\dirtree{%
.1 src.
.2 Geometry.
.3 mesh.py.
.3 cell.py.
.3 line.py.
.3 triangle.py.
.2 Simulation.
.3 plotter.py.
.3 simulation.py.
.3 solver.py.
.2 InputOutput.  
.3 commandlineParser.py.
.3 log.py.
.3 tomlParser.py.
}

The folder structure is split into three packages,
each with their own functionalities and purposes.
The Geometry package, as the name suggests, handles
data relating to the geometry provided. It has classes
for the various different cell types, and a class for handling
the mesh data, and by extension, centralizing the data from the
cell classes.
\\\\
The InputOutput package handles data relating to user input and output.
In this case, the user input is config file(s) in toml format
and command-line arguments. The user output is a log file. As such,
this package has one class for each of those functionalities.
A class to handle logging, a class to read and parse command-line
arguments, and a class to parse and provide the data of toml files.
\\\\
The Simulation is the most central package, and contains classes that handle the data
relating to the actual simulation. It has a plotter class
that handles the various aspects of visualization of data,
including image and video creation. The solver class implements
all the formulas needed in the simulation, putting the advanced math
in one place. The simulation class brings those two together,
handling the overall logic needed to make use of the tools provided
in the two other classes. The simulation class also brings the other two packages
together, and thus is the most complex class in our project. Because this
particular class relies on everything else, writing unit tests that only relied
on this class's logic was difficult. However, with the other classes having
their own unit tests, the location of a potential problem can be safely assumed based
on the overall context.
\\\\
The separation of these packages made the program more structured and
easier to work with. Because of how independent these packages are,
it also increased testability, as we could quickly write isolated
tests for almost everything added. The packages aren't entirely independent of course,
as some utilization of each other is necessary to actually get a simulation.
We managed to avoid circular dependencies though, and worked hard to make each
class as independent of other classes as possible, and to keep necessary dependancy
as linear as possible.

\section{UML-diagram}

\begin{figure}[H]
    \includegraphics[width=1.2\textwidth]{Figures/UML-diagram-final.png}
    \caption{Final UML diagram}
\end{figure}
The UML diagram above showcases what was described in the folder structure
section. Everything is centralized on simulation, no class except for simulation
is fully dependant on more than one other class. Thus, the flow of the program is
intuitive to follow, and the project could be built step by step by utilizing
concepts from the scrum process, further described in the next section.

\chapter{Agile development}
Agile development is an iterative approach to software creation that emphasizes flexibility and
collaboration. The main idea is breaking a complex problem into smaller parts.  
Through small, frequent releases of working software, 
the strategy will produce results that are getting closer and closer to achieve the end goal.

\section{Story map and 3rd party software}
Our approach implementing agile development was firstly to clarify expectations to eachother working in a group.
Secondly, we spent the first days reading and understanding the problem thoroughly. 
By breaking the problem down to smaller pieces, we got a clear idea about what solutions
the problem would require. By identifying this, we structured the work by creating a story map.
\subsection{StoriesOnBoard}
We used a 3rd party software from https://StoriesOnBoard.com with a 14 days free trail in order to facilitate agile development. 
We chose StoriesOnBoard because it offerd more features than native github projects, it had a nice layout, user firendly gui, and the ability to integrate with GitHub. 
Focusing on documentation, organizing the main structre, we achieved a foundtation to start tackeling the problem. 
Applying timelines and sprints, we also gained an idea to when certian taskes was supposed to be done.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Figures/StoryBoard.png}
    \caption{Story map}
\end{figure}

Our story map follows a traditional setup with Epics at the top, user stories on the second level  and taskes bellow their respective user story.
The tasks were assigned under a Sprint that was set with a duration of 5 days. 
The tasks emphasizes detailed decription and checkmarks within the task, rather then a big quantity of tasks in order to have a clear overview in the Story map.
If a task where missing certain elements, rather then creating new issues or sub issues,
it gave a better overview to edit description and add checkmarks.

\newpage
\begin{figure}[H]
\centering
\begin{minipage}{.45\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/ExampleTask.png}
\end{minipage}\hfill%
\begin{minipage}{.45\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/ExampleTask2.png}
\end{minipage}

\vspace{0.5em}

\begin{minipage}{.65\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/ExampleTask3.png}
\end{minipage}
\caption{Example of tasks}
\end{figure}

Looking at some examples of tasks created on StoriesOnBoard, to demonstrate several features with agile development. 
It has instantanious replication to github issues. The possiblity to stage multiple issues and bulk push them was useful. 
This enables us to keep an overview and it assured creation of good descriptions and to think through what the issue would required for completion.
A task could have multiple attriubutes for weiging through priority, difficulty and effect. 
By having this 3rd party software, we where able to systematicly and visualy structre the project through agile development principles.


\section{github}

Implementing continuous integration (CI) with GitHub Actions and tox streamlined the project testing across multiple environments.
The benefits with continuous integration is all about catching regressions early through automated linting, unit tests, and cross-version compatibility checks. 
This setup ensures reliability before merging pull requests. 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Figures/CI.png}
    \caption{Implementation of contionous integration in github actions}
\end{figure}

As demonstrated, having implemented continous integration early on, 
gave significant help throughout the project, assuring working code before merging.


\chapter{Results}



% Bibliography
\blankpage\printbibliography

\end{document}